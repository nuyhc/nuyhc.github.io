---
title: "멋쟁이 사자처럼 AI Shcool 8주차"

categories: [Retrospective, AI School]
tags:
    - likelion
---

## 6월 20일
- Kaggle Titaninc 데이터를 이용한 실습
- 엔트로피(entropy)
- 배깅(bagging)
  - 부트스트랩을 통해 조금씩 다른 훈련 데이터에 대해 훈련된 기초 분류기들을 결합 시키는 방법

## 6월 21일
- 랜덤 포레스트 (Random Forest)
- 배깅은 병렬로, 부스팅은 순차적으로 실행
- `RandomSearchCV`를 이용한 하이퍼파라미터 튜닝
- bike-sharing-demand 경진대회
- `cross_val_predict`을 사용하는 경우, 다양한 평가 방식을 적용해 볼 수 있음
- 교차 검증하고 모델 사용하는 방법이 너무 헷갈림.. 너무 왔다갔다해서 그런가..
- `cross_val_~` 함수를 써서 검증한 경우, 따로 `fit`을 시켜야 함

## 6월 22일
- `log1p`와 `expm1`을 이용해, taget을 변환하고 복구해 학습 및 성능 평가를 하는 방법
  - `RMSLE` = `neg_root_mean_squared_error`
  - 너무 큰 값, 편향된 값들을 평탄화 시켜주는 과정
  - 일반적으로, 왜도, 첨도가 높을 때 로그를 통해 정규분포로 바꾼다
- 신호와 소음을 잘 구분하자
- Kaggle House Prices 회귀 실습
- Feature Engineering(특성 공학)
  - EDA가 중요
  - 통계적 개념이 많이 적용됨
  - Categorical
      - Nominal: 순서가 없음 (성별, 음료수 종류)
      - Ordinal: 자연적인 순서가 있음 (성적, 등급)
  - Numeric
      - Discete: 유한 (물건의 개수, 행동 횟수)
      - Contunuous: 무한 (물건의 개수, 시간)
- 종류
  - 특성 선택(Feature Selection)
  - 특성 추출(Feature Extraction)
  - 범위 변환(Scaling)
      - StandardScaler(Z-score): 평균을 제거하고 데이터를 단위 분산에 맞게 조정
      - Min-Max: 지정된 범위로 확장하여 기능을 변환 (default=[0,1])
      - Robust: 중앙값을 제거하고 분위수(default=IQR)에 따라 데이터 크기를 조정 -> boxplot
  - 변형(Transform)
  - 범주화(Binning)
  - 숫자화(Dummy)

## 6월 23일
- 스트리밍 처리
- TDD: 프로그래밍 과정에서의 의사결정과 피드백 사이의 간극을 인식하고, 이 간극을 제어하는 기법
- `error`와 `fale`은 다름
- 다시 음식 추천 프로그램으로 돌아옴
- 단위 테스트
  - 테스트를 하고 싶은 부분을 최대한 쪼개서 테스트를 진행
  - 클램핑(clamping): 범위가 벗어난 경우, 억지로 범위 이내로 넣어주는 것
- 비결정론적/확률적 기능 테스트
  - 되도록 순수 함수 형태로 바꿔서 테스트
  - 순수 함수 형태가 불가능한 경우 시드를 고정
- **정규 표현식**: 언어를 정의하는 언어
  - Quantifier:
      - ? (0개 또는 1개)
      - \+ (1개 또는 그 이상)
      - \* (0개 또는 그 이상)
      - \+? (1개 또는 그 이상, non-greedy)
      - \*? (0개 또는 그 이상, non-greedy)
      - {2,5} (2개 이상 5개 이하)
  - Character class:
      - ^ (시작)
      - $ (끝)
      - \w (임의의 영단어나 숫자)
      - \a (임의의 영단어)
      - \s (공백 또는 탭 또는 줄바꿈)
      - [abc] (a 또는 b 또는 c)
      - [0-9] (0 또는 1 또는 2 또는 … 8 또는 9)
      - [a-z] (a 또는 b 또는 c 또는 … y 또는 z)
  - 분기 또는 그룹: (alan\|brad) (alan 또는 brad)

## 6월 24일
- Tableau 특강

## 요약
- 기본적인 머신러닝 분류와 회귀를 배웠음
- 조금 헷갈리는 부분들이 있지만, 대체로 제대로 이해하고 있는거 같음
- 모델의 성능을 높이기 위해, EDA가 중요하다는걸 캐글이나 데이콘에 제출해보면서 느낌
  - EDA를하는 베이스라인은 정해졌는데, 추가적으로 필요하거나 파생변수 생성/삭제 등에 있어서는 많이 부족한거 같음
  - 시각화 부분도..
- 정규표현식은 연습이 필요할꺼 같음

