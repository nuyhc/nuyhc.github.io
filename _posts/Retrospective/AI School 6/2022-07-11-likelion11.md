---
title: "멋쟁이 사자처럼 AI School 11주차"

categories: [Retrospective, AI School]
tags:
    - likelion
---

## 7월 11일
- `Numpy`
  - `np.ones`는 `shape`가 들어가고, `np.ones_like`는 `array의 shape`가 들어감
  - 이미지 데이터에 `np.transpose`를 사용하면, 이미지가 회전함
  - `view(얕은 복사)`는 원본에 영향을, `copy(깊은 복사)`는 원본에 영향을 주지 않음
  - `a@b` = `np.dot(a,b)` = `np.matmul`
- CNN (Convolution Neural Network, 합성곱 신경망)
  - 이미지 데이터에서, 주변 정보를 연결해 보고자할 때 사용 (인접 데이터를 조사해 특징을 파악)
  - 픽셀마다 다른 가중치를 부여함
- 특징 추출 영역: 합성곱층(필터 적용, 활성화 함수 반영)과 풀링층(선택적)을 여러 겹 쌓은 형태
  - 필터: 각 레이어의 입출력 데이터의 형상 유지, 복수의 필터로 이미지의 특징 추출 및 학습 (수용영역, 필터, 커널)
- Flatten 레이어: 추출된 주요 특징을 FC에 전달하기 위해 이미지 데이터를 배열 형태(1차원)로 전환
- 클래스 분류 영역: CNN 마지막 부분에는 분류를 위한 FC 추가


--- 


- 필터(Filter): 공용 파라미터로 학습의 대상이며, 합성곱의 가중치에 해당
- 커널(Kernel): sliding window하는 영역에서의 크기
- 스트라이드(Stride): 필터를 적용하는 간격
- 패딩(Padding): 외곽에 지정된 픽셀만큼 특정 값으로 채워 넣음
  - `valid`: 유효한 영역만 출력
  - `same`: 출력과 입력의 사이즈 동일
- 채널(Channel): 여러개의 채널을 가진 1개의 커널 (RGB)
- 특징맵(Feature Map): 필터가 순회하며 합성곱을 통해 만든 출력
- 액티베이션 맵(Activation Map): 피쳐 맵에 활성화 함수를 적용한 최종 출력층
- 풀링(Pooling): 출력 데이터의 크기를 줄이거나 특정 데이터를 강종
  - 행렬의 크기는 감소하지만 채널 수 변경은 없음
  - `Max`, `Min`, `Average`
- 데이터 증강(Data Augmentation)
- `openCV`

## 7월 12일
- CNN
- Overlapping Pooling: 커널 사이즈 > 스트라이드
- 성능저하 (degradation)
- 전이학습과 미세 조정(Tranfer Learning / Fine Tuning)
- `OpenCV`는 `BRG`형태로 이미지를 불러와, `RGB` 형태로 변경할 필요가 있음
- `sigmoid`: 이진 / `softmax`: 다중
- 정형 데이터의 경우 `sklearn`의 기능을 사용 가능

## 7월 13일
- `tensorflow`에서, `validation_split` 지정시 균일하게 나눠지지 않음 -> `sklearn`의 `train_test_split` 이용
- 이미지 데이터는 클래스마다 폴더를 만들어 관리하는 편
- 이진 분류: `Dense(1, activation="sigmoid")`
- 다중 분류: `Dense(class #, activation="softmax")`
- 데이터 증강

## 7월 14일
- OOP
- UML
- 코드 리뷰를하는 좋은 방법
  - Test case 추가
  - 주석 추가
  - 리팩토링
- 애자일 방법론에서는 설계를 안한다 -> X -> 작은 설계를 함
- 큰 설계를 미리 다 하지 않는다(Big Design Up Front)
- 단일책임원칙(SRP, Single Responsibility Principle)

## 7월 15일
- 재귀함수 (Top-Down 방식): 느림, 코드 직관적
- 반복문 (Bottom-Up 방식): 빠름, 상대적으로 복잡
- `from functools import lru_cache`
- decorator
  - 공통적으로 기능을 추가시 활용
- closer(factory func)
  - 지역 변수와 코드를 묶어서 사용하고 싶을 때 활용
  - 은닉화
- 재귀함수
- 트리

## 요약
- 머신러닝에서는 하이퍼파라미터 튜닝을 잘 진행하지 않았는데, 딥러닝에서는 잘 활용해봐야겠다.
- 자료구조와 알고리즘 공부를 빨리 시작할것
- OpenCV도 공부하면 좋을꺼 같음